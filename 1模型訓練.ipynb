{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 快速開始\n",
    "這裡可以看到所有pytorch會用到的基本步驟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下載範例資料集\n",
    "# FashionMNIST 是個經典的影像處理資料集\n",
    "# 裡面有各式各樣的服裝、鞋子等\n",
    "# 現實中會用到許多資料集，都需要轉換為Tensor的資料型態才能進行訓練(會在TensorTurtorial中詳細介紹)\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root='basic_dataset', # 設定下載的目錄\n",
    "    train=True, # 是否取得訓練子集\n",
    "    download=True, # 如果本地端沒有資料是否從原始網站中下載\n",
    "    transform=ToTensor() # 轉換\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='basic_dataset',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "建立的是資料集的形式，並定義在讀取資料到輸入到模型的整個流程\n",
    "裡面的流程包含了前處理，舉例來說在影像處理中可能會進行resize、高斯模糊、銳化等前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.data # 原始資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一筆資料的影像 = tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
      "          0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0039, 0.0039, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
      "          0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
      "          0.0157, 0.0000, 0.0000, 0.0118],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
      "          0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0471, 0.0392, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
      "          0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
      "          0.3020, 0.5098, 0.2824, 0.0588],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
      "          0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
      "          0.5529, 0.3451, 0.6745, 0.2588],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
      "          0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
      "          0.4824, 0.7686, 0.8980, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
      "          0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
      "          0.8745, 0.9608, 0.6784, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
      "          0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
      "          0.8627, 0.9529, 0.7922, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
      "          0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
      "          0.8863, 0.7725, 0.8196, 0.2039],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
      "          0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
      "          0.9608, 0.4667, 0.6549, 0.2196],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
      "          0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
      "          0.8510, 0.8196, 0.3608, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
      "          0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
      "          0.8549, 1.0000, 0.3020, 0.0000],\n",
      "         [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
      "          0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
      "          0.8784, 0.9569, 0.6235, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
      "          0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
      "          0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
      "          0.9137, 0.9333, 0.8431, 0.0000],\n",
      "         [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
      "          0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
      "          0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
      "          0.8627, 0.9098, 0.9647, 0.0000],\n",
      "         [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
      "          0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
      "          0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
      "          0.8706, 0.8941, 0.8824, 0.0000],\n",
      "         [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
      "          0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
      "          0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
      "          0.8745, 0.8784, 0.8980, 0.1137],\n",
      "         [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
      "          0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
      "          0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
      "          0.8627, 0.8667, 0.9020, 0.2627],\n",
      "         [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
      "          0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
      "          0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
      "          0.7098, 0.8039, 0.8078, 0.4510],\n",
      "         [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
      "          0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
      "          0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
      "          0.6549, 0.6941, 0.8235, 0.3608],\n",
      "         [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
      "          0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
      "          0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
      "          0.7529, 0.8471, 0.6667, 0.0000],\n",
      "         [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
      "          0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
      "          0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
      "          0.3882, 0.2275, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
      "          0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "標籤 = 9\n"
     ]
    }
   ],
   "source": [
    "print(f'第一筆資料的影像 = {training_data[0][0]}') #第一筆資料的影像\n",
    "print(f'標籤 = {training_data[0][1]}') #第一筆資料的標籤"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "建立的是資料從資料集中取出的過程\n",
    "這個過程可能為一次取出幾筆資料(Batch)、是否每次都為隨機存取、一次有多個CPU取資料等設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size 為一次給模型看幾筆資料，再進行學習\n",
    "\n",
    "batch_size = 16\n",
    "# Dataloader 將資料取得的資料集做整合，並以batch的形式輸出\n",
    "train_dataloader = DataLoader(training_data, batch_size = batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(train_dataloader)) # 封裝成迭代器的形式取出第一個batch的資料 \n",
    "# 也可以使用 for 迴圈來直接存取資料\n",
    "for (X, y) in train_dataloader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X 的 Shape 屬性\n",
      "torch.Size([16, 1, 28, 28]) 分別代表(Batch, Channel, Height, Width)\n"
     ]
    }
   ],
   "source": [
    "# 檢查資料的shape 屬性\n",
    "print(f'X 的 Shape 屬性')\n",
    "print(f'{X.size()} 分別代表(Batch, Channel, Height, Width)')\n",
    "# 因為是灰階圖所以Channel數為1個 而高與寬接固定為1\n",
    "# 另外因為剛剛設定batch size為16所以一次會有16筆資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 確認GPU是否已啟用\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# 定義簡單的模型\n",
    "# 這是一個簡單的神經網路模型\n",
    "# 概念就是將剛剛取出來的影像攤平(16, 1, 28, 28) -> (16, 1*28*28)\n",
    "# 透過線性層做轉換輸出為10(因為有十個類別)\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "# 查看神經網路模型\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 784])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([10, 512])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# 查看神經網路細部的參數\n",
    "for parm in model.parameters():\n",
    "    print(parm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 套入損失函數以及優化器\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.314163  [    0/60000]\n",
      "loss: 2.289094  [ 1600/60000]\n",
      "loss: 2.274062  [ 3200/60000]\n",
      "loss: 2.274224  [ 4800/60000]\n",
      "loss: 2.254732  [ 6400/60000]\n",
      "loss: 2.240305  [ 8000/60000]\n",
      "loss: 2.203576  [ 9600/60000]\n",
      "loss: 2.185208  [11200/60000]\n",
      "loss: 2.199120  [12800/60000]\n",
      "loss: 2.141027  [14400/60000]\n",
      "loss: 2.123219  [16000/60000]\n",
      "loss: 2.078492  [17600/60000]\n",
      "loss: 2.093282  [19200/60000]\n",
      "loss: 2.072254  [20800/60000]\n",
      "loss: 2.055300  [22400/60000]\n",
      "loss: 1.987503  [24000/60000]\n",
      "loss: 1.962314  [25600/60000]\n",
      "loss: 2.013845  [27200/60000]\n",
      "loss: 1.887687  [28800/60000]\n",
      "loss: 1.900014  [30400/60000]\n",
      "loss: 1.776666  [32000/60000]\n",
      "loss: 1.704933  [33600/60000]\n",
      "loss: 1.621958  [35200/60000]\n",
      "loss: 1.763187  [36800/60000]\n",
      "loss: 1.794955  [38400/60000]\n",
      "loss: 1.592060  [40000/60000]\n",
      "loss: 1.561033  [41600/60000]\n",
      "loss: 1.627460  [43200/60000]\n",
      "loss: 1.319094  [44800/60000]\n",
      "loss: 1.476009  [46400/60000]\n",
      "loss: 1.489112  [48000/60000]\n",
      "loss: 1.285640  [49600/60000]\n",
      "loss: 1.363042  [51200/60000]\n",
      "loss: 1.345156  [52800/60000]\n",
      "loss: 1.240818  [54400/60000]\n",
      "loss: 1.363436  [56000/60000]\n",
      "loss: 1.229781  [57600/60000]\n",
      "loss: 1.018269  [59200/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.3%, Avg loss: 1.235035 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 所有訓練資料丟入給模型訓練\n",
    "size = len(train_dataloader.dataset)\n",
    "model.train() # 將模型轉換為訓練模式\n",
    "for batch, (X, y) in enumerate(train_dataloader):\n",
    "    # 將優化器梯度清零 將優化器梯度清零 將優化器梯度清零 !!!! 因為很重要所以要講三次\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 將資料傳輸到GPU記憶體\n",
    "    X, y = X.to(device), y.to(device)\n",
    "\n",
    "    # 丟入模型預測結果\n",
    "    pred = model(X)\n",
    "\n",
    "    # 將預測結果與真實標籤做loss值計算\n",
    "    loss = loss_fn(pred, y)\n",
    "\n",
    "    # 執行反向傳播影演算法\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "        loss, current = loss.item(), batch * len(X)\n",
    "        print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "# 驗收訓練成果\n",
    "size = len(test_dataloader.dataset)\n",
    "num_batches = len(test_dataloader)\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X, y in test_dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        test_loss += loss_fn(pred, y).item()\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "test_loss /= num_batches\n",
    "correct /= size\n",
    "print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPOCH\n",
    "剛剛做的是將訓練資料丟入訓練後驗收測試結果而事實上我們會丟入很多次訓練資料\n",
    "模型看過一次所有訓練資料的我們稱之為一個Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.272104  [    0/60000]\n",
      "loss: 1.113373  [ 1600/60000]\n",
      "loss: 1.156306  [ 3200/60000]\n",
      "loss: 1.215863  [ 4800/60000]\n",
      "loss: 1.096035  [ 6400/60000]\n",
      "loss: 1.248352  [ 8000/60000]\n",
      "loss: 1.190179  [ 9600/60000]\n",
      "loss: 1.052225  [11200/60000]\n",
      "loss: 1.082846  [12800/60000]\n",
      "loss: 1.094201  [14400/60000]\n",
      "loss: 1.145958  [16000/60000]\n",
      "loss: 0.945697  [17600/60000]\n",
      "loss: 0.874017  [19200/60000]\n",
      "loss: 1.456032  [20800/60000]\n",
      "loss: 1.091043  [22400/60000]\n",
      "loss: 1.075808  [24000/60000]\n",
      "loss: 0.828840  [25600/60000]\n",
      "loss: 1.147608  [27200/60000]\n",
      "loss: 1.162052  [28800/60000]\n",
      "loss: 1.013543  [30400/60000]\n",
      "loss: 0.928576  [32000/60000]\n",
      "loss: 0.631915  [33600/60000]\n",
      "loss: 0.753212  [35200/60000]\n",
      "loss: 0.968003  [36800/60000]\n",
      "loss: 1.290683  [38400/60000]\n",
      "loss: 0.809842  [40000/60000]\n",
      "loss: 0.906116  [41600/60000]\n",
      "loss: 0.916365  [43200/60000]\n",
      "loss: 0.637109  [44800/60000]\n",
      "loss: 0.854541  [46400/60000]\n",
      "loss: 0.844580  [48000/60000]\n",
      "loss: 0.725345  [49600/60000]\n",
      "loss: 0.771576  [51200/60000]\n",
      "loss: 0.834425  [52800/60000]\n",
      "loss: 0.828081  [54400/60000]\n",
      "loss: 1.146424  [56000/60000]\n",
      "loss: 0.855566  [57600/60000]\n",
      "loss: 0.625360  [59200/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.7%, Avg loss: 0.864112 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.878398  [    0/60000]\n",
      "loss: 0.726387  [ 1600/60000]\n",
      "loss: 0.760849  [ 3200/60000]\n",
      "loss: 0.835242  [ 4800/60000]\n",
      "loss: 0.733054  [ 6400/60000]\n",
      "loss: 0.889500  [ 8000/60000]\n",
      "loss: 0.911718  [ 9600/60000]\n",
      "loss: 0.683488  [11200/60000]\n",
      "loss: 0.825218  [12800/60000]\n",
      "loss: 0.737198  [14400/60000]\n",
      "loss: 0.895575  [16000/60000]\n",
      "loss: 0.645724  [17600/60000]\n",
      "loss: 0.616003  [19200/60000]\n",
      "loss: 1.353824  [20800/60000]\n",
      "loss: 0.817736  [22400/60000]\n",
      "loss: 0.880731  [24000/60000]\n",
      "loss: 0.580849  [25600/60000]\n",
      "loss: 0.977570  [27200/60000]\n",
      "loss: 1.083270  [28800/60000]\n",
      "loss: 0.757690  [30400/60000]\n",
      "loss: 0.756453  [32000/60000]\n",
      "loss: 0.421769  [33600/60000]\n",
      "loss: 0.539509  [35200/60000]\n",
      "loss: 0.747619  [36800/60000]\n",
      "loss: 1.178795  [38400/60000]\n",
      "loss: 0.683983  [40000/60000]\n",
      "loss: 0.778975  [41600/60000]\n",
      "loss: 0.710508  [43200/60000]\n",
      "loss: 0.498583  [44800/60000]\n",
      "loss: 0.683975  [46400/60000]\n",
      "loss: 0.663342  [48000/60000]\n",
      "loss: 0.570426  [49600/60000]\n",
      "loss: 0.586832  [51200/60000]\n",
      "loss: 0.682530  [52800/60000]\n",
      "loss: 0.736347  [54400/60000]\n",
      "loss: 1.048562  [56000/60000]\n",
      "loss: 0.782771  [57600/60000]\n",
      "loss: 0.538740  [59200/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 0.747588 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.769825  [    0/60000]\n",
      "loss: 0.637511  [ 1600/60000]\n",
      "loss: 0.656448  [ 3200/60000]\n",
      "loss: 0.679799  [ 4800/60000]\n",
      "loss: 0.604312  [ 6400/60000]\n",
      "loss: 0.736961  [ 8000/60000]\n",
      "loss: 0.800145  [ 9600/60000]\n",
      "loss: 0.539865  [11200/60000]\n",
      "loss: 0.718534  [12800/60000]\n",
      "loss: 0.551180  [14400/60000]\n",
      "loss: 0.829670  [16000/60000]\n",
      "loss: 0.520846  [17600/60000]\n",
      "loss: 0.516075  [19200/60000]\n",
      "loss: 1.249996  [20800/60000]\n",
      "loss: 0.682676  [22400/60000]\n",
      "loss: 0.798272  [24000/60000]\n",
      "loss: 0.513449  [25600/60000]\n",
      "loss: 0.911321  [27200/60000]\n",
      "loss: 1.000734  [28800/60000]\n",
      "loss: 0.639809  [30400/60000]\n",
      "loss: 0.726968  [32000/60000]\n",
      "loss: 0.343496  [33600/60000]\n",
      "loss: 0.453085  [35200/60000]\n",
      "loss: 0.633175  [36800/60000]\n",
      "loss: 1.046164  [38400/60000]\n",
      "loss: 0.663901  [40000/60000]\n",
      "loss: 0.720003  [41600/60000]\n",
      "loss: 0.617487  [43200/60000]\n",
      "loss: 0.451527  [44800/60000]\n",
      "loss: 0.609134  [46400/60000]\n",
      "loss: 0.556320  [48000/60000]\n",
      "loss: 0.504390  [49600/60000]\n",
      "loss: 0.472360  [51200/60000]\n",
      "loss: 0.586442  [52800/60000]\n",
      "loss: 0.699401  [54400/60000]\n",
      "loss: 0.936921  [56000/60000]\n",
      "loss: 0.745207  [57600/60000]\n",
      "loss: 0.486962  [59200/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.679276 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.689798  [    0/60000]\n",
      "loss: 0.596917  [ 1600/60000]\n",
      "loss: 0.609142  [ 3200/60000]\n",
      "loss: 0.584671  [ 4800/60000]\n",
      "loss: 0.518612  [ 6400/60000]\n",
      "loss: 0.646640  [ 8000/60000]\n",
      "loss: 0.733177  [ 9600/60000]\n",
      "loss: 0.455592  [11200/60000]\n",
      "loss: 0.634584  [12800/60000]\n",
      "loss: 0.430605  [14400/60000]\n",
      "loss: 0.803300  [16000/60000]\n",
      "loss: 0.440063  [17600/60000]\n",
      "loss: 0.453282  [19200/60000]\n",
      "loss: 1.180702  [20800/60000]\n",
      "loss: 0.586455  [22400/60000]\n",
      "loss: 0.742402  [24000/60000]\n",
      "loss: 0.488756  [25600/60000]\n",
      "loss: 0.851034  [27200/60000]\n",
      "loss: 0.913987  [28800/60000]\n",
      "loss: 0.564748  [30400/60000]\n",
      "loss: 0.714578  [32000/60000]\n",
      "loss: 0.295663  [33600/60000]\n",
      "loss: 0.393951  [35200/60000]\n",
      "loss: 0.548901  [36800/60000]\n",
      "loss: 0.924613  [38400/60000]\n",
      "loss: 0.668825  [40000/60000]\n",
      "loss: 0.681810  [41600/60000]\n",
      "loss: 0.558116  [43200/60000]\n",
      "loss: 0.432541  [44800/60000]\n",
      "loss: 0.558091  [46400/60000]\n",
      "loss: 0.485977  [48000/60000]\n",
      "loss: 0.466846  [49600/60000]\n",
      "loss: 0.390751  [51200/60000]\n",
      "loss: 0.510148  [52800/60000]\n",
      "loss: 0.677674  [54400/60000]\n",
      "loss: 0.831344  [56000/60000]\n",
      "loss: 0.712036  [57600/60000]\n",
      "loss: 0.442691  [59200/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.630429 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.633619  [    0/60000]\n",
      "loss: 0.559261  [ 1600/60000]\n",
      "loss: 0.584133  [ 3200/60000]\n",
      "loss: 0.521951  [ 4800/60000]\n",
      "loss: 0.450267  [ 6400/60000]\n",
      "loss: 0.587117  [ 8000/60000]\n",
      "loss: 0.685759  [ 9600/60000]\n",
      "loss: 0.399440  [11200/60000]\n",
      "loss: 0.568616  [12800/60000]\n",
      "loss: 0.348746  [14400/60000]\n",
      "loss: 0.789845  [16000/60000]\n",
      "loss: 0.378226  [17600/60000]\n",
      "loss: 0.412900  [19200/60000]\n",
      "loss: 1.139281  [20800/60000]\n",
      "loss: 0.515387  [22400/60000]\n",
      "loss: 0.698920  [24000/60000]\n",
      "loss: 0.475007  [25600/60000]\n",
      "loss: 0.796604  [27200/60000]\n",
      "loss: 0.832822  [28800/60000]\n",
      "loss: 0.511611  [30400/60000]\n",
      "loss: 0.694891  [32000/60000]\n",
      "loss: 0.262164  [33600/60000]\n",
      "loss: 0.347269  [35200/60000]\n",
      "loss: 0.480862  [36800/60000]\n",
      "loss: 0.826043  [38400/60000]\n",
      "loss: 0.679586  [40000/60000]\n",
      "loss: 0.660380  [41600/60000]\n",
      "loss: 0.512020  [43200/60000]\n",
      "loss: 0.431062  [44800/60000]\n",
      "loss: 0.520210  [46400/60000]\n",
      "loss: 0.441312  [48000/60000]\n",
      "loss: 0.441314  [49600/60000]\n",
      "loss: 0.335685  [51200/60000]\n",
      "loss: 0.448171  [52800/60000]\n",
      "loss: 0.663207  [54400/60000]\n",
      "loss: 0.742565  [56000/60000]\n",
      "loss: 0.681112  [57600/60000]\n",
      "loss: 0.408563  [59200/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.594502 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    size = len(train_dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    size = len(test_dataloader.dataset)\n",
    "    num_batches = len(test_dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('torchEnv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "856971fa0a169429db2bf0c06b69517a5be6dea1d062d3d5bb82efdd1c5fddc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
