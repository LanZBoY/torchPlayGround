{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wen2Tee5\\Desktop\\Postgraduate\\torchPlayGround\\torchEnv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mNLPUtils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessUtils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m removePunctuation, removeWord\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mNLPUtils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDataModel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Vocabulary\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfTransformer\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n",
      "File \u001b[1;32mc:\\Users\\Wen2Tee5\\Desktop\\Postgraduate\\torchPlayGround\\torchEnv\\lib\\site-packages\\sklearn\\__init__.py:82\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _distributor_init  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m __check_build  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m clone\n\u001b[0;32m     83\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_show_versions\u001b[39;00m \u001b[39mimport\u001b[39;00m show_versions\n\u001b[0;32m     85\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[0;32m     86\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcalibration\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     87\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcluster\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mshow_versions\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    129\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\Wen2Tee5\\Desktop\\Postgraduate\\torchPlayGround\\torchEnv\\lib\\site-packages\\sklearn\\base.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_config\u001b[39;00m \u001b[39mimport\u001b[39;00m get_config\n\u001b[1;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m _IS_32BIT\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_tags\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     19\u001b[0m     _DEFAULT_TAGS,\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvalidation\u001b[39;00m \u001b[39mimport\u001b[39;00m check_X_y\n",
      "File \u001b[1;32mc:\\Users\\Wen2Tee5\\Desktop\\Postgraduate\\torchPlayGround\\torchEnv\\lib\\site-packages\\sklearn\\utils\\__init__.py:29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m DataConversionWarning\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdeprecation\u001b[39;00m \u001b[39mimport\u001b[39;00m deprecated\n\u001b[1;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfixes\u001b[39;00m \u001b[39mimport\u001b[39;00m parse_version, threadpool_info\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_estimator_html_repr\u001b[39;00m \u001b[39mimport\u001b[39;00m estimator_html_repr\n\u001b[0;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mvalidation\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     32\u001b[0m     as_float_array,\n\u001b[0;32m     33\u001b[0m     assert_all_finite,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m     check_scalar,\n\u001b[0;32m     42\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Wen2Tee5\\Desktop\\Postgraduate\\torchPlayGround\\torchEnv\\lib\\site-packages\\sklearn\\utils\\fixes.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mthreadpoolctl\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_config\u001b[39;00m \u001b[39mimport\u001b[39;00m config_context, get_config\n",
      "File \u001b[1;32mc:\\Users\\Wen2Tee5\\Desktop\\Postgraduate\\torchPlayGround\\torchEnv\\lib\\site-packages\\scipy\\stats\\__init__.py:467\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m.. _statsrefmanual:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    462\u001b[0m \n\u001b[0;32m    463\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_warnings_errors\u001b[39;00m \u001b[39mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[0;32m    466\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[1;32m--> 467\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_stats_py\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    468\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_variation\u001b[39;00m \u001b[39mimport\u001b[39;00m variation\n\u001b[0;32m    469\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdistributions\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Wen2Tee5\\Desktop\\Postgraduate\\torchPlayGround\\torchEnv\\lib\\site-packages\\scipy\\stats\\_stats_py.py:53\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_stats\u001b[39;00m \u001b[39mimport\u001b[39;00m (_kendall_dis, _toint64, _weightedrankedtau,\n\u001b[0;32m     51\u001b[0m                      _local_correlations)\n\u001b[0;32m     52\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdataclasses\u001b[39;00m \u001b[39mimport\u001b[39;00m make_dataclass\n\u001b[1;32m---> 53\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_hypotests\u001b[39;00m \u001b[39mimport\u001b[39;00m _all_partitions\n\u001b[0;32m     54\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_hypotests_pythran\u001b[39;00m \u001b[39mimport\u001b[39;00m _compute_outer_prob_inside_method\n\u001b[0;32m     55\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_resampling\u001b[39;00m \u001b[39mimport\u001b[39;00m _batch_generator\n",
      "File \u001b[1;32mc:\\Users\\Wen2Tee5\\Desktop\\Postgraduate\\torchPlayGround\\torchEnv\\lib\\site-packages\\scipy\\stats\\_hypotests.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_continuous_distns\u001b[39;00m \u001b[39mimport\u001b[39;00m chi2, norm\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspecial\u001b[39;00m \u001b[39mimport\u001b[39;00m gamma, kv, gammaln\n\u001b[1;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfft\u001b[39;00m \u001b[39mimport\u001b[39;00m ifft\n\u001b[0;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_hypotests_pythran\u001b[39;00m \u001b[39mimport\u001b[39;00m _a_ij_Aij_Dij2\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_hypotests_pythran\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     15\u001b[0m     _concordant_pairs \u001b[39mas\u001b[39;00m _P, _discordant_pairs \u001b[39mas\u001b[39;00m _Q\n\u001b[0;32m     16\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Wen2Tee5\\Desktop\\Postgraduate\\torchPlayGround\\torchEnv\\lib\\site-packages\\scipy\\fft\\__init__.py:92\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_fftlog\u001b[39;00m \u001b[39mimport\u001b[39;00m fhtoffset\n\u001b[0;32m     91\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_fftlog_multimethods\u001b[39;00m \u001b[39mimport\u001b[39;00m fht, ifht\n\u001b[1;32m---> 92\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_helper\u001b[39;00m \u001b[39mimport\u001b[39;00m next_fast_len\n\u001b[0;32m     93\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_backend\u001b[39;00m \u001b[39mimport\u001b[39;00m (set_backend, skip_backend, set_global_backend,\n\u001b[0;32m     94\u001b[0m                        register_backend)\n\u001b[0;32m     95\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfft\u001b[39;00m \u001b[39mimport\u001b[39;00m fftfreq, rfftfreq, fftshift, ifftshift\n",
      "File \u001b[1;32mc:\\Users\\Wen2Tee5\\Desktop\\Postgraduate\\torchPlayGround\\torchEnv\\lib\\site-packages\\scipy\\fft\\_helper.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfunctools\u001b[39;00m \u001b[39mimport\u001b[39;00m update_wrapper, lru_cache\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_pocketfft\u001b[39;00m \u001b[39mimport\u001b[39;00m helper \u001b[39mas\u001b[39;00m _helper\n\u001b[0;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnext_fast_len\u001b[39m(target, real\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m      7\u001b[0m     \u001b[39m\"\"\"Find the next fast size of input data to ``fft``, for zero-padding, etc.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[39m    SciPy's FFT algorithms gain their speed by a recursive divide and conquer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Wen2Tee5\\Desktop\\Postgraduate\\torchPlayGround\\torchEnv\\lib\\site-packages\\scipy\\fft\\_pocketfft\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\" FFT backend using pypocketfft \"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbasic\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mrealtransforms\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mhelper\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Wen2Tee5\\Desktop\\Postgraduate\\torchPlayGround\\torchEnv\\lib\\site-packages\\scipy\\fft\\_pocketfft\\basic.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfunctools\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m pypocketfft \u001b[39mas\u001b[39;00m pfft\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mhelper\u001b[39;00m \u001b[39mimport\u001b[39;00m (_asfarray, _init_nd_shape_and_axes, _datacopied,\n\u001b[0;32m      8\u001b[0m                      _fix_shape, _fix_shape_1d, _normalization,\n\u001b[0;32m      9\u001b[0m                      _workers)\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mc2c\u001b[39m(forward, x, n\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, norm\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, overwrite_x\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     12\u001b[0m         workers\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m, plan\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     13\u001b[0m     \u001b[39m\"\"\" Return discrete Fourier transform of real or complex sequence. \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1002\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:945\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1439\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1411\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1577\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:161\u001b[0m, in \u001b[0;36m_path_isfile\u001b[1;34m(path)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:153\u001b[0m, in \u001b[0;36m_path_is_mode_type\u001b[1;34m(path, mode)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import dgl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from NLPUtils.preprocessUtils import removePunctuation, removeWord\n",
    "from NLPUtils.DataModel import Vocabulary\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = '.\\\\R8'\n",
    "TRAIN = 'train.txt'\n",
    "TEST = 'test.txt'\n",
    "MAXLEN = 30\n",
    "TOKEN = {'<unk>' : 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removeWordList = stopwords.words('english')\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(ROOT, TRAIN), encoding='utf-8',sep='\\t', header=None)\n",
    "df_test = pd.read_csv(os.path.join(ROOT, TRAIN), encoding='utf-8', sep = '\\t', header=None)\n",
    "label2idx = {label : i for i, label in enumerate(df_train[0].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = Vocabulary(TOKENS=TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentence = []\n",
    "test_sentence = []\n",
    "for sentence in df_train[1]:\n",
    "    sentence = removePunctuation(sentence=sentence)\n",
    "    sentence = removeWord(removeWordList=removeWordList, sentence=sentence)\n",
    "    train_sentence.append(sentence)\n",
    "for sentence in df_test[1]:\n",
    "    sentence = removePunctuation(sentence=sentence)\n",
    "    sentence = removeWord(removeWordList=removeWordList, sentence=sentence)\n",
    "    test_sentence.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算tf-idf權重並建立詞彙庫\n",
    "vector = CountVectorizer(token_pattern=r'\\S+')\n",
    "table = vector.fit_transform(train_sentence)\n",
    "tfidf = TfidfTransformer()\n",
    "tfidfTable = tfidf.fit_transform(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = Vocabulary(TOKENS={'<PAD>' : 0, '<UNK>' : 1})\n",
    "voc.addWordList(vector.get_feature_names_out().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將資料encode為idx\n",
    "train_idxs = []\n",
    "for sentence in train_sentence:\n",
    "    data = sentence.split()[:MAXLEN]\n",
    "    train_idx = [voc.word2idx[word] for word in data]\n",
    "    while len(train_idx) < MAXLEN:\n",
    "        train_idx.append(voc.word2idx['<PAD>'])\n",
    "    train_idxs.append(train_idx)\n",
    "\n",
    "test_idxs = []\n",
    "for sentence in test_sentence:\n",
    "    data = sentence.split()[:MAXLEN]\n",
    "    test_idx = []\n",
    "    for word in data:\n",
    "        if voc.has(word):\n",
    "            test_idx.append(voc.word2idx[word])\n",
    "        else:\n",
    "            test_idx.append(voc.word2idx['<UNK>'])\n",
    "    while len(test_idx) < MAXLEN:\n",
    "        test_idx.append(voc.word2idx['<PAD>'])\n",
    "    test_idxs.append(test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(train_idxs, dtype=np.int64)\n",
    "x_test = np.array(test_idxs, dtype=np.int64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('torchEnv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "856971fa0a169429db2bf0c06b69517a5be6dea1d062d3d5bb82efdd1c5fddc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
