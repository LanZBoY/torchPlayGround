{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wen2Tee5\\Desktop\\Postgraduate\\torchPlayGround\\torchEnv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'he is a king',\n",
    "    'she is a queen',\n",
    "    'he is a man',\n",
    "    'she is a woman',\n",
    "    'warsaw is poland capital',\n",
    "    'berlin is germany capital',\n",
    "    'paris is france capital',\n",
    "    \"\"\"\n",
    "    When forty winters shall besiege thy brow,\n",
    "    And dig deep trenches in thy beauty's field,\n",
    "    Thy youth's proud livery so gazed on now,\n",
    "    Will be a totter'd weed of small worth held:\n",
    "    Then being asked, where all thy beauty lies,\n",
    "    Where all the treasure of thy lusty days;\n",
    "    To say, within thine own deep sunken eyes,\n",
    "    Were an all-eating shame, and thriftless praise.\n",
    "    How much more praise deserv'd thy beauty's use,\n",
    "    If thou couldst answer 'This fair child of mine\n",
    "    Shall sum my count, and make my old excuse,'\n",
    "    Proving his beauty by succession thine!\n",
    "    This were to be new made when thou art old,\n",
    "    And see thy blood warm when thou feel'st it cold.\n",
    "    \"\"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_corpus(corpus):\n",
    "    tokens = [x.split() for x in corpus]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = tokenize_corpus(corpus=corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['he', 'is', 'a', 'king'], ['she', 'is', 'a', 'queen'], ['he', 'is', 'a', 'man'], ['she', 'is', 'a', 'woman'], ['warsaw', 'is', 'poland', 'capital'], ['berlin', 'is', 'germany', 'capital'], ['paris', 'is', 'france', 'capital'], ['When', 'forty', 'winters', 'shall', 'besiege', 'thy', 'brow,', 'And', 'dig', 'deep', 'trenches', 'in', 'thy', \"beauty's\", 'field,', 'Thy', \"youth's\", 'proud', 'livery', 'so', 'gazed', 'on', 'now,', 'Will', 'be', 'a', \"totter'd\", 'weed', 'of', 'small', 'worth', 'held:', 'Then', 'being', 'asked,', 'where', 'all', 'thy', 'beauty', 'lies,', 'Where', 'all', 'the', 'treasure', 'of', 'thy', 'lusty', 'days;', 'To', 'say,', 'within', 'thine', 'own', 'deep', 'sunken', 'eyes,', 'Were', 'an', 'all-eating', 'shame,', 'and', 'thriftless', 'praise.', 'How', 'much', 'more', 'praise', \"deserv'd\", 'thy', \"beauty's\", 'use,', 'If', 'thou', 'couldst', 'answer', \"'This\", 'fair', 'child', 'of', 'mine', 'Shall', 'sum', 'my', 'count,', 'and', 'make', 'my', 'old', \"excuse,'\", 'Proving', 'his', 'beauty', 'by', 'succession', 'thine!', 'This', 'were', 'to', 'be', 'new', 'made', 'when', 'thou', 'art', 'old,', 'And', 'see', 'thy', 'blood', 'warm', 'when', 'thou', \"feel'st\", 'it', 'cold.']]\n"
     ]
    }
   ],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sentences:\n",
    "     for word in sentence:\n",
    "        if word not in voc:\n",
    "            voc.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'is', 'a', 'king', 'she', 'queen', 'man', 'woman', 'warsaw', 'poland', 'capital', 'berlin', 'germany', 'paris', 'france', 'When', 'forty', 'winters', 'shall', 'besiege', 'thy', 'brow,', 'And', 'dig', 'deep', 'trenches', 'in', \"beauty's\", 'field,', 'Thy', \"youth's\", 'proud', 'livery', 'so', 'gazed', 'on', 'now,', 'Will', 'be', \"totter'd\", 'weed', 'of', 'small', 'worth', 'held:', 'Then', 'being', 'asked,', 'where', 'all', 'beauty', 'lies,', 'Where', 'the', 'treasure', 'lusty', 'days;', 'To', 'say,', 'within', 'thine', 'own', 'sunken', 'eyes,', 'Were', 'an', 'all-eating', 'shame,', 'and', 'thriftless', 'praise.', 'How', 'much', 'more', 'praise', \"deserv'd\", 'use,', 'If', 'thou', 'couldst', 'answer', \"'This\", 'fair', 'child', 'mine', 'Shall', 'sum', 'my', 'count,', 'make', 'old', \"excuse,'\", 'Proving', 'his', 'by', 'succession', 'thine!', 'This', 'were', 'to', 'new', 'made', 'when', 'art', 'old,', 'see', 'blood', 'warm', \"feel'st\", 'it', 'cold.']\n"
     ]
    }
   ],
   "source": [
    "print(voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {w:idx for (idx, w) in enumerate(voc)}\n",
    "inx2word = {idx:w for (idx, w) in enumerate(voc)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-gram\n",
    "CONTEXT_SIZE = 2\n",
    "idx_pair = []\n",
    "for sentence in sentences:\n",
    "    for i in range(CONTEXT_SIZE, len(sentence)):\n",
    "        context = [sentence[i - j - 1] for j in range(CONTEXT_SIZE)]\n",
    "        target = sentence[i]\n",
    "        idx_pair.append((context, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['is', 'he'], 'a')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_pair[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class embedding(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim) -> None:\n",
    "        super(embedding, self).__init__()\n",
    "        self.tableW = torch.nn.Parameter(torch.randn((vocab_size, embedding_dim), requires_grad=True))\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "    def forward(self, idx):\n",
    "        return self.tableW[idx]\n",
    "\n",
    "\n",
    "\n",
    "class NGramLanguageModeler(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size) -> None:\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = torch.nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = torch.nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x).view((1, -1)) # 這邊的想法是concat兩個tensor的向量後統合一個結果\n",
    "        x = torch.nn.functional.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        x = torch.nn.functional.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "loss_function = torch.nn.NLLLoss()\n",
    "model = NGramLanguageModeler(len(voc), 10, CONTEXT_SIZE)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4958,  1.1488, -0.7197, -1.9668,  0.3909,  0.0794, -0.9873, -0.6977,\n",
       "          0.1854, -0.1827],\n",
       "        [ 0.2638, -2.2044,  0.7035, -0.4912,  1.7612,  0.3545,  2.4088,  1.5987,\n",
       "         -1.5484,  0.7278],\n",
       "        [ 1.1533,  2.8507,  1.6373,  0.4407, -0.8464, -0.3718, -0.6306,  0.1699,\n",
       "         -0.7330,  0.0181]], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings(torch.tensor(data=[1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    for context, target in idx_pair:\n",
    "        context_idxs = torch.tensor([word2idx[w] for w in context], dtype=torch.long)\n",
    "        model.zero_grad()\n",
    "        log_probs = model(context_idxs)\n",
    "        loss = loss_function(log_probs, torch.tensor([word2idx[target]], dtype=torch.long))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[598.7933633327484,\n",
       " 595.6715388298035,\n",
       " 592.5725803375244,\n",
       " 589.4955089092255,\n",
       " 586.4399955272675,\n",
       " 583.4038963317871,\n",
       " 580.3849759101868,\n",
       " 577.3839056491852,\n",
       " 574.3989176750183,\n",
       " 571.4298176765442,\n",
       " 568.4764256477356,\n",
       " 565.5374565124512,\n",
       " 562.6128051280975,\n",
       " 559.701164484024,\n",
       " 556.8011193275452,\n",
       " 553.9107966423035,\n",
       " 551.0319902896881,\n",
       " 548.1663072109222,\n",
       " 545.3142218589783,\n",
       " 542.476115822792,\n",
       " 539.6519093513489,\n",
       " 536.8428168296814,\n",
       " 534.0483647584915,\n",
       " 531.2678909301758,\n",
       " 528.5019017457962,\n",
       " 525.7524298429489,\n",
       " 523.0173176527023,\n",
       " 520.2961111068726,\n",
       " 517.590426325798,\n",
       " 514.897775888443,\n",
       " 512.2192373275757,\n",
       " 509.55303502082825,\n",
       " 506.89947444200516,\n",
       " 504.25756990909576,\n",
       " 501.62536519765854,\n",
       " 499.00207644701004,\n",
       " 496.38615822792053,\n",
       " 493.7772195339203,\n",
       " 491.1718570590019,\n",
       " 488.5691973567009,\n",
       " 485.9689711332321,\n",
       " 483.3662385940552,\n",
       " 480.76508498191833,\n",
       " 478.1642761826515,\n",
       " 475.5609430074692,\n",
       " 472.95479705929756,\n",
       " 470.34450829029083,\n",
       " 467.72822764515877,\n",
       " 465.1058475971222,\n",
       " 462.479246199131,\n",
       " 459.84612756967545,\n",
       " 457.2069215476513,\n",
       " 454.5612816810608,\n",
       " 451.9104236662388,\n",
       " 449.25151401758194,\n",
       " 446.58527985215187,\n",
       " 443.91325959563255,\n",
       " 441.2311924993992,\n",
       " 438.54088124632835,\n",
       " 435.8441924750805,\n",
       " 433.13578087091446,\n",
       " 430.41927668452263,\n",
       " 427.6933896243572,\n",
       " 424.9601294696331,\n",
       " 422.21762800216675,\n",
       " 419.46493422985077,\n",
       " 416.7035879790783,\n",
       " 413.9339839220047,\n",
       " 411.15517497062683,\n",
       " 408.365591019392,\n",
       " 405.5678314715624,\n",
       " 402.7602651566267,\n",
       " 399.9422438889742,\n",
       " 397.11619514226913,\n",
       " 394.2802909016609,\n",
       " 391.43640042841434,\n",
       " 388.5829428881407,\n",
       " 385.72000385820866,\n",
       " 382.84907472133636,\n",
       " 379.9716848433018,\n",
       " 377.0848815739155,\n",
       " 374.1902853101492,\n",
       " 371.2875069528818,\n",
       " 368.3797399997711,\n",
       " 365.46398466825485,\n",
       " 362.5399146527052,\n",
       " 359.6099750548601,\n",
       " 356.6744106709957,\n",
       " 353.7340024113655,\n",
       " 350.78720323741436,\n",
       " 347.835992410779,\n",
       " 344.8794175684452,\n",
       " 341.91852098703384,\n",
       " 338.95437544584274,\n",
       " 335.9833125472069,\n",
       " 333.0105536878109,\n",
       " 330.03257861733437,\n",
       " 327.0517739057541,\n",
       " 324.07062144577503,\n",
       " 321.08453573286533]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses # The loss decreased every iteration over the training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('torchEnv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "856971fa0a169429db2bf0c06b69517a5be6dea1d062d3d5bb82efdd1c5fddc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
