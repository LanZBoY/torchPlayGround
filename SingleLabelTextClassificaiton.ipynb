{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wen2Tee5\\Desktop\\machine learning\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDB_file = './basic_dataset/IMDB/IMDB Dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, csv_file, MAX_LEN = 100):\n",
    "        self.dataframe = pd.read_csv(csv_file)\n",
    "        self.tokenizer = get_tokenizer(\"basic_english\")\n",
    "        self.voc = build_vocab_from_iterator(self.yield_tokens(self.dataframe.review), specials=['<unk>'])\n",
    "        self.voc.set_default_index(self.voc['<unk>'])\n",
    "        self.text_pipeline = lambda x : self.fixed_size(max_len = MAX_LEN, voc = self.voc(self.tokenizer(x)))\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # 應該想辦法轉換成tensor\n",
    "        if(self.dataframe.sentiment[index] == 'positive'):\n",
    "            y = torch.tensor(data=1)\n",
    "        else:\n",
    "            y = torch.tensor(data=0)\n",
    "        x = torch.tensor(self.text_pipeline(self.dataframe.review[index]))\n",
    "        return x, y\n",
    "\n",
    "\n",
    "    def yield_tokens(self, data_iter):\n",
    "        for text in data_iter:\n",
    "            yield self.tokenizer(text)\n",
    "\n",
    "    @staticmethod\n",
    "    def fixed_size(max_len, voc = []):\n",
    "        if len(voc) > max_len:\n",
    "            return voc[:max_len]\n",
    "        while len(voc) < max_len:\n",
    "            voc.append(0)\n",
    "        return voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = IMDBDataset(IMDB_file, MAX_LEN=200)\n",
    "IMDBDataloader = DataLoader(dataset=dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    1,  2603,     9,    40,  4264,   900,     3,     5, 11776,  1214,\n",
      "           91,    28,    69,     1,  3863,   343,     6,     5,  1561,   486,\n",
      "            3,    21,    90,    91,    34,     6,     5,    60,  1026,   172,\n",
      "            2,    13,     9, 29374,  2041,     6,    54,    57,    33,  3167,\n",
      "           50,   404,  3257, 16283,    72, 15361, 12331,     2,    13,     9,\n",
      "        25329,    36,   169,     3,  4039,  1150,  2235,     7,   764,    91,\n",
      "        17579,     4,  6325,     4,  1822,   146,   370,  1850,     2,    13,\n",
      "            9,     1,   125,    20,     6,     1,   339,     7,  1317,     2,\n",
      "           12,     8,   145,   341,  1904,  5145,    49,    13,    22,     3,\n",
      "         1678,    42,    37,   438,     4,    64,  2374,     7,   868,   184,\n",
      "          109,     4,    85,   120,     2,     7, 16529,  6507,    13,    22,\n",
      "            9,     7,   694,     1,   228,     2,    13,    20,   206,    33,\n",
      "            5,  8599,     3,     5,  2981,   121,   715,   106,    87,  2195,\n",
      "          856,     2,     1,  2603,    52,    47,  3008,     1,  1290,     7,\n",
      "          164,   185,     6,  1558,     2,    43,    57,    76,  9648,     1,\n",
      "         1290,    11,    98,   411,     4,   377,    10,     4,    98,   172,\n",
      "        20369, 12398,    14,    76,    94,     8,    26,   187,   107,    59,\n",
      "           53,  1236,     3,    12,    66,    59,    79,  2505,   164,    20,\n",
      "           39, 20369,     3,     4,    66,   119,     7,    71,   287,   355,\n",
      "            7,  2970,    95,     2,    76,     8,   145,    37,   548,   701])\n"
     ]
    }
   ],
   "source": [
    "x,_ = dataset[26]\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "torch.Size([128, 200])\n"
     ]
    }
   ],
   "source": [
    "for x,y in IMDBDataloader:\n",
    "    print(y.shape)\n",
    "    print(x.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset=dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class) -> None:\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def init_weight(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "    \n",
    "    def forward(self, text):\n",
    "        x = self.embedding(text)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcModel = TextClassificationModel(len(dataset.voc), embed_dim= 256, num_class=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(tcModel.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55702\n",
      "0.59708\n",
      "0.61166\n",
      "0.617\n",
      "0.62196\n",
      "0.62674\n",
      "0.63092\n",
      "0.63472\n",
      "0.63856\n",
      "0.64164\n",
      "0.64498\n",
      "0.64822\n",
      "0.6505\n",
      "0.65282\n",
      "0.65482\n",
      "0.65716\n",
      "0.6597\n",
      "0.6621\n",
      "0.66478\n",
      "0.66678\n",
      "0.66902\n",
      "0.67098\n",
      "0.67274\n",
      "0.67434\n",
      "0.67612\n",
      "0.67798\n",
      "0.67966\n",
      "0.68214\n",
      "0.68364\n",
      "0.68592\n",
      "0.68762\n",
      "0.68984\n",
      "0.69178\n",
      "0.69354\n",
      "0.69492\n",
      "0.69614\n",
      "0.69752\n",
      "0.69894\n",
      "0.70018\n",
      "0.7019\n",
      "0.70312\n",
      "0.70448\n",
      "0.7059\n",
      "0.70664\n",
      "0.70818\n",
      "0.70942\n",
      "0.71036\n",
      "0.71172\n",
      "0.713\n",
      "0.7142\n",
      "0.71544\n",
      "0.7167\n",
      "0.71772\n",
      "0.71864\n",
      "0.71978\n",
      "0.7207\n",
      "0.7216\n",
      "0.7226\n",
      "0.72402\n",
      "0.72502\n",
      "0.72606\n",
      "0.727\n",
      "0.72824\n",
      "0.72874\n",
      "0.72948\n",
      "0.73028\n",
      "0.73112\n",
      "0.73172\n",
      "0.7328\n",
      "0.73354\n",
      "0.7345\n",
      "0.73562\n",
      "0.73626\n",
      "0.73734\n",
      "0.73836\n",
      "0.73888\n",
      "0.73928\n",
      "0.73984\n",
      "0.74044\n",
      "0.74142\n",
      "0.74178\n",
      "0.74274\n",
      "0.74334\n",
      "0.74392\n",
      "0.74438\n",
      "0.74508\n",
      "0.74596\n",
      "0.7465\n",
      "0.74742\n",
      "0.74792\n",
      "0.74866\n",
      "0.74934\n",
      "0.75006\n",
      "0.75064\n",
      "0.75144\n",
      "0.75234\n",
      "0.75288\n",
      "0.75342\n",
      "0.75414\n",
      "0.75464\n"
     ]
    }
   ],
   "source": [
    "tcModel.train()\n",
    "for epoch in range(100):\n",
    "    total_acc, total_count = 0, 0\n",
    "    correct = 0.\n",
    "    for x,y in data_loader:\n",
    "        x, y= x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = tcModel(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    acc = correct/len(dataset)\n",
    "    print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcModel.eval()\n",
    "correct = 0\n",
    "for i,(x,y) in enumerate(data_loader):\n",
    "    x, y= x.to(device), y.to(device)\n",
    "    pred = tcModel(x)\n",
    "    correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "acc = correct/len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75572\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipline = dataset.text_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4936, 0.5064]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Positive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred = tcModel(torch.tensor(text_pipline(\"Seriously what is wrong with critics I loved this retailing\")).view(size=(1, 200)).to(device=device))\n",
    "print(pred)\n",
    "if pred.argmax(1) ==1:\n",
    "    print('Positive')\n",
    "else:\n",
    "    print('negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_Result(commend:str):\n",
    "    pred = tcModel(torch.tensor(text_pipline(commend)).view(size=(1, 200)).to(device=device))\n",
    "    print(pred)\n",
    "    if pred.argmax(1) ==1:\n",
    "        print('Positive')\n",
    "    else:\n",
    "        print('negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4936, 0.5064]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Positive\n",
      "tensor([[0.2516, 0.7484]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Positive\n",
      "tensor([[0.8335, 0.1665]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "negative\n",
      "tensor([[0.9267, 0.0733]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "# groundTruth good\n",
    "show_Result(\"Seriously what is wrong with critics I loved this retailing\")\n",
    "show_Result(\"It's funny! It's rhythmic!! It's spectacular!!!\")\n",
    "# groundTruth bad\n",
    "show_Result(\"Disney strikes back with yet another live-action remake disaster that soils the name of the original movies. Aladdin (2019) is a confused mess. It not only adds nothing remarkable on to the original to justify it's existence, but Aladdin is a movie that only works in animation, because in live-action it's identity is just lost. The CGI is abominable. Despite a few scenes where it's OK, the CGI overall is shockingly bad for a Disney film and it's even more depressing that they sunk so much money into it. The Genie specifically is one of the worst looking CGI characters I've seen in some time. And more on the Genie; I've seen a lot of people say that they like Will Smith's Genie, and while I will commend Smith for not trying to imitate Robin Williams' Genie and for doing his on thing, it's just not working for me. They also butchered a lot of the songs, specifically 'Friend Like Me' and 'Prince Ali'. Not only can Will Smith not sing to save his life and the songs have been 69'd by autotune, but they've also added some new lines and lyrics into them as well as changing their flow and energy at times. While it's fine to add some differences from the original, this is the wrong kind of different. No one wanted the songs to be changed and the new lyrics are OK at best and shockingly bad at worst. The flow and tone of the songs has also been changed and that's probably due to Will Smith's singing, because what made Robin Williams' Genie great is the sheer amount of incredible energy he gave which is also what made 'Friend Like Me' and 'Prince Ali' so fun and catchy. Here, Will Smith completely butchers these songs, especially Prince Ali' because of how slow and boring it is compared to the original. Finally, the movie is just pointless. It doesn't justify it's existence at all. Why would I want to watch a boring and slow version of the original with none of the colourful, expressive animation and humour when I can watch the original, at ANY TIME, which has the expressive animation and humour? It's a pointless and unoriginal bore of a film that I will not be seeing again.\")\n",
    "show_Result(\"What's to say. Before even filming we knew Guy Ritchie was obviously the wrong choice to direct the film. His style doesn't quite lend itself to this type of film. Miscast Mena Massoud didn't bring any real character to the role of Aladdin he was simply okay/ functional. Will Smith is as usual charismatic and had difficult shoes to fill after Robin Williams' take on the genie but he was seriously let down by the VFX in blue genie mode and a weak script. Another miscast Naomi Scott gave a good performance but I always felt i was looking at Indian and not Middle Eastern. In fact the film IS very bollywood with the Jasmin, Aladdin dance off Indian Style (and to Indian music) then Russian dancing(?) plus other times an Indian soundtrack. And i'm not even going to talk about that sorry excuse for a villain. No, no i am not. For a Disney movie set in large Kingdom it sure does feel quite quite small. It looked cheap too. Weird. Ultimately a dreadfully executed cash grab of a movie that no one asked for. Thanks D. Thankfully this is exactly what i expected having seen the trailers.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('pytorch': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69465f8012bc8209665d9cbe96a44652f48a74cf23ffa7f2a4d4373e52b4e5fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
