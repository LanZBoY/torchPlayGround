{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wen2Tee5\\Desktop\\Postgraduate\\torchPlayGround\\torchEnv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import string\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(torch.nn.Module):\n",
    "    def __init__(self, voc_size, embedding_dim) -> None:\n",
    "        super(Word2Vec, self).__init__()\n",
    "        # Encoder\n",
    "        self.w1 = torch.nn.Parameter(torch.randn(size=(embedding_dim, voc_size), requires_grad = True))\n",
    "        self.b1 = torch.nn.Parameter(torch.randn(size = (embedding_dim,), requires_grad= True))\n",
    "        \n",
    "        # Decoder\n",
    "        self.w2 = torch.nn.Parameter(torch.randn(size=(voc_size ,embedding_dim ), requires_grad = True))\n",
    "        self.b2 = torch.nn.Parameter(torch.randn(size=(voc_size,), requires_grad = True))\n",
    "    def forward(self, x):\n",
    "        x = x @ self.w1.T + self.b1\n",
    "        x = x @ self.w2.T + self.b2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBDatasetSLTCWithEmbedding(Dataset):\n",
    "\n",
    "    def __init__(self,file_path, voc_path, train = True, DEVICE = 'cpu', max_len = 30) -> None:\n",
    "        super(IMDBDatasetSLTCWithEmbedding, self).__init__()\n",
    "        with open('./NLPUtils/english.txt', 'r', encoding='utf-8') as f:\n",
    "            self.stop_words = [stop_word.replace('\\n', '') for stop_word in f.readlines()]\n",
    "        self.df = pd.read_csv(file_path, encoding='utf-8')\n",
    "        with open(voc_path, 'rb') as f:\n",
    "            self.voc = pickle.load(f)\n",
    "            self.word2idx = {word:idx for idx, word in enumerate(self.voc)}\n",
    "            self.idx2word = {idx:word for idx, word in enumerate(self.voc)}\n",
    "        self.w1 : torch.Tensor = torch.load('./trained_models/word2vecW1.pth')\n",
    "        self.w1.requires_grad = False\n",
    "        self.b1 : torch.Tensor = torch.load('./trained_models/word2vecB1.pth')\n",
    "        self.b1.requires_grad = False\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x_sentence = self.df['review'][index].translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "        x_tokens = self.tokenize(x_sentence)\n",
    "        for stop_word in self.stop_words:\n",
    "            x_tokens = list(filter(stop_word.__ne__, x_tokens))\n",
    "        x_idx_list = [self.word2idx[word] for word in x_tokens]\n",
    "        x_one_hot_list = []\n",
    "        for idx in x_idx_list:\n",
    "            one_hot = np.zeros(shape=(len(self.voc)))\n",
    "            one_hot[idx] = 1.\n",
    "            x_one_hot_list.append(one_hot)\n",
    "        while len(x_one_hot_list) < self.max_len:\n",
    "            one_hot = np.zeros(shape=(len(self.voc)))\n",
    "            x_one_hot_list.append(one_hot)\n",
    "        x_one_hot = np.array(x_one_hot_list[:self.max_len])\n",
    "        x = torch.from_numpy(x_one_hot).type(torch.float32).to(DEVICE)\n",
    "        x = x @ self.w1.T + self.b1\n",
    "        y = torch.tensor(data=[1.]).to(DEVICE) if self.df['sentiment'][index] =='positive' else torch.tensor(data=[0.]).to(DEVICE)\n",
    "        return x, y\n",
    "\n",
    "    def tokenize(self, x_sentence) -> list:\n",
    "        tokens = x_sentence.split()\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, freeze_trainedModel = False) -> None:\n",
    "        super(Classifier, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(300, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        x = x.mean(dim = 1)\n",
    "        x = self.linear1(x)\n",
    "        return self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './basic_dataset/IMDB/IMDB Dataset.csv'\n",
    "voc_path = './basic_dataset/IMDB/voc.data'\n",
    "imdbDataset = IMDBDatasetSLTCWithEmbedding(file_path=file_path, voc_path = voc_path, DEVICE = DEVICE)\n",
    "imdbDataLoder = DataLoader(imdbDataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.3144,  0.0205, -0.0961,  ..., -0.2552,  0.2956, -0.1508],\n",
       "         [ 0.1272, -0.2211, -0.0283,  ...,  0.0989, -0.0653, -0.0479],\n",
       "         [-0.1842,  0.2885, -0.1961,  ..., -0.1633,  0.1446,  0.1732],\n",
       "         ...,\n",
       "         [ 0.1751,  0.2198, -0.0398,  ..., -0.1864, -0.0751, -0.2856],\n",
       "         [-0.2499,  0.4340,  0.1951,  ...,  0.7701, -0.1244, -0.2998],\n",
       "         [ 0.0557, -0.0204,  0.0038,  ...,  0.0275,  0.0430,  0.0873]],\n",
       "        device='cuda:0'),\n",
       " tensor([1.], device='cuda:0'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdbDataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier().to(DEVICE)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 166/1563 [02:09<18:06,  1.29it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m tqdm(imdbDataLoder):\n\u001b[0;32m      2\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m      3\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\n",
      "File \u001b[1;32mc:\\Users\\Wen2Tee5\\Desktop\\Postgraduate\\torchPlayGround\\torchEnv\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Wen2Tee5\\Desktop\\Postgraduate\\torchPlayGround\\torchEnv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Wen2Tee5\\Desktop\\Postgraduate\\torchPlayGround\\torchEnv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Wen2Tee5\\Desktop\\Postgraduate\\torchPlayGround\\torchEnv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Wen2Tee5\\Desktop\\Postgraduate\\torchPlayGround\\torchEnv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn [4], line 35\u001b[0m, in \u001b[0;36mIMDBDatasetSLTCWithEmbedding.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     33\u001b[0m     one_hot \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvoc)))\n\u001b[0;32m     34\u001b[0m     x_one_hot_list\u001b[38;5;241m.\u001b[39mappend(one_hot)\n\u001b[1;32m---> 35\u001b[0m x_one_hot \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_one_hot_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_len\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(x_one_hot)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     37\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw1\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb1\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for x, y in tqdm(imdbDataLoder):\n",
    "    pred = model(x)\n",
    "    loss = loss_fn(pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('torchEnv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "856971fa0a169429db2bf0c06b69517a5be6dea1d062d3d5bb82efdd1c5fddc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
