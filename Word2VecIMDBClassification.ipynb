{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wen2Tee5\\Desktop\\machine learning\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import string\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "EPOCH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(torch.nn.Module):\n",
    "    def __init__(self, voc_size, embedding_dim) -> None:\n",
    "        super(Word2Vec, self).__init__()\n",
    "        # Encoder\n",
    "        self.w1 = torch.nn.Parameter(torch.randn(size=(embedding_dim, voc_size), requires_grad = True))\n",
    "        self.b1 = torch.nn.Parameter(torch.randn(size = (embedding_dim,), requires_grad= True))\n",
    "        \n",
    "        # Decoder\n",
    "        self.w2 = torch.nn.Parameter(torch.randn(size=(voc_size, embedding_dim), requires_grad = True))\n",
    "        self.b2 = torch.nn.Parameter(torch.randn(size=(voc_size,), requires_grad = True))\n",
    "    def forward(self, x):\n",
    "        x = self.w1 @ x + self.b1\n",
    "        x = self.w2 @ x + self.b2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = []\n",
    "with open('./NLPUtils/english.txt', encoding='utf-8') as f:\n",
    "    stop_words = [stop_word.replace('\\n','') for stop_word in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './basic_dataset/IMDB/IMDB Dataset.csv'\n",
    "\n",
    "df = pd.read_csv(file_path, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [sentence.lower() for sentence in df['review'][:200]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 66655.61it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(sentences))):\n",
    "    sentences[i] = sentences[i].translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentences) -> list:\n",
    "    tokens = [sentence.split() for sentence in sentences]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenize(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 240.33it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(tokens))):\n",
    "    for stop_word in stop_words:\n",
    "        tokens[i] = list(filter(stop_word.__ne__, tokens[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 8693.94it/s]\n"
     ]
    }
   ],
   "source": [
    "for sentence in tqdm(sentences):\n",
    "     for word in sentence:\n",
    "        if word not in voc:\n",
    "            voc.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {w:idx for (idx, w) in enumerate(voc)}\n",
    "inx2word = {idx:w for (idx, w) in enumerate(voc)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 219.01it/s]\n"
     ]
    }
   ],
   "source": [
    "window_size = 3\n",
    "idx_pair = []\n",
    "for sentence in tqdm(sentences):\n",
    "    indices = [word2idx[word] for word in sentence]\n",
    "    for idx in range(len(indices)):\n",
    "        if idx + window_size - 1 < len(indices):\n",
    "            window = indices[idx : idx + window_size]\n",
    "            for x_word in window:\n",
    "                for y_word in window:\n",
    "                    if x_word != y_word:\n",
    "                        idx_pair.append([x_word, y_word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_vector = torch.zeros(size=(len(voc), len(voc)),requires_grad= False).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, vector in enumerate(one_hot_vector):\n",
    "    vector[idx] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(voc_size=len(voc), embedding_dim=EMBEDDING_DIM).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1517320/1517320 [26:19<00:00, 960.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss 1.999158501625061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1517320/1517320 [26:52<00:00, 940.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss 2.0371532440185547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1517320/1517320 [26:32<00:00, 952.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss 2.018064260482788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1517320/1517320 [26:32<00:00, 952.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss 2.001497268676758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1517320/1517320 [26:30<00:00, 954.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss 2.0146384239196777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1517320/1517320 [26:29<00:00, 954.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss 2.016083240509033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 281292/1517320 [04:55<21:38, 951.63it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [18], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# correct += (pred.argmax(0) == y.argmax(0)).float()\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# print(f'Acc = {correct/len(idx_pair)}')\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCurrent loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Wen2Tee5\\Desktop\\machine learning\\pytorch\\lib\\site-packages\\torch\\optim\\optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Wen2Tee5\\Desktop\\machine learning\\pytorch\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Wen2Tee5\\Desktop\\machine learning\\pytorch\\lib\\site-packages\\torch\\optim\\adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mmax_exp_avg_sq\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    155\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m--> 157\u001b[0m     adam(params_with_grad,\n\u001b[0;32m    158\u001b[0m          grads,\n\u001b[0;32m    159\u001b[0m          exp_avgs,\n\u001b[0;32m    160\u001b[0m          exp_avg_sqs,\n\u001b[0;32m    161\u001b[0m          max_exp_avg_sqs,\n\u001b[0;32m    162\u001b[0m          state_steps,\n\u001b[0;32m    163\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    164\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    165\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    166\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    167\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    168\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    169\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    170\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    171\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m    173\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\Wen2Tee5\\Desktop\\machine learning\\pytorch\\lib\\site-packages\\torch\\optim\\adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 213\u001b[0m func(params,\n\u001b[0;32m    214\u001b[0m      grads,\n\u001b[0;32m    215\u001b[0m      exp_avgs,\n\u001b[0;32m    216\u001b[0m      exp_avg_sqs,\n\u001b[0;32m    217\u001b[0m      max_exp_avg_sqs,\n\u001b[0;32m    218\u001b[0m      state_steps,\n\u001b[0;32m    219\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    220\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    221\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    222\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[0;32m    223\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[0;32m    224\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[0;32m    225\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[0;32m    226\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable)\n",
      "File \u001b[1;32mc:\\Users\\Wen2Tee5\\Desktop\\machine learning\\pytorch\\lib\\site-packages\\torch\\optim\\adam.py:263\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    262\u001b[0m exp_avg\u001b[39m.\u001b[39mmul_(beta1)\u001b[39m.\u001b[39madd_(grad, alpha\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta1)\n\u001b[1;32m--> 263\u001b[0m exp_avg_sq\u001b[39m.\u001b[39;49mmul_(beta2)\u001b[39m.\u001b[39;49maddcmul_(grad, grad\u001b[39m.\u001b[39;49mconj(), value\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m beta2)\n\u001b[0;32m    265\u001b[0m \u001b[39mif\u001b[39;00m capturable:\n\u001b[0;32m    266\u001b[0m     step \u001b[39m=\u001b[39m step_t\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(word2vec.parameters(), lr=1e-3)\n",
    "for epch in range(20):\n",
    "    # correct = 0.\n",
    "    for x,y in tqdm(idx_pair):\n",
    "        optimizer.zero_grad()\n",
    "        y = one_hot_vector[y]\n",
    "        x = one_hot_vector[x]\n",
    "        pred = word2vec(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        # correct += (pred.argmax(0) == y.argmax(0)).float()\n",
    "        optimizer.step()\n",
    "    # print(f'Acc = {correct/len(idx_pair)}')\n",
    "    print(f'Current loss {loss.item()}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(word2vec, 'word2vec.ph')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(len(voc), embedding_dim=EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('w1',\n",
       "              tensor([[-0.7570, -1.1619,  1.5999,  ..., -0.1433, -0.8304,  1.0122],\n",
       "                      [-1.4809, -0.9033, -0.3666,  ..., -3.3922, -1.0577,  0.7802],\n",
       "                      [-0.4891, -2.2955, -1.0598,  ...,  1.7060,  0.2266,  0.2450],\n",
       "                      ...,\n",
       "                      [-0.9563, -0.9016, -0.1940,  ...,  0.1345, -0.8428,  0.5069],\n",
       "                      [ 0.7356,  0.8071,  0.0396,  ..., -0.2778, -0.9067, -0.8001],\n",
       "                      [-1.2157, -0.4392, -0.1110,  ...,  0.3787,  1.3319,  0.1884]])),\n",
       "             ('b1',\n",
       "              tensor([ 1.3634e+00, -1.5701e+00,  4.2080e-01, -1.5758e-01,  2.6060e-01,\n",
       "                       1.9533e+00, -7.5437e-01,  2.2399e-01, -7.0086e-01,  9.5323e-01,\n",
       "                      -1.1076e+00, -1.5141e+00, -7.6550e-01, -6.7069e-01,  4.9201e-01,\n",
       "                       5.2997e-02,  8.0617e-01, -5.5404e-01,  9.9680e-01,  5.5406e-01,\n",
       "                       6.5434e-01, -3.8817e-01, -8.7488e-02,  2.8059e-01,  6.1494e-01,\n",
       "                       3.1701e-01,  1.7334e+00,  6.7455e-02, -4.4260e-01, -8.1141e-01,\n",
       "                       6.3384e-01,  1.5452e-01,  8.3549e-01, -7.8743e-01, -6.1096e-01,\n",
       "                       1.0051e+00,  1.5359e+00,  5.1220e-02, -6.9917e-02,  4.4246e-01,\n",
       "                      -1.7669e+00, -2.0176e-01,  9.9621e-01,  6.0878e-01, -6.8205e-01,\n",
       "                      -5.2889e-01, -3.4719e-01, -1.2008e+00,  4.0019e-01, -1.4078e+00,\n",
       "                       1.3333e-01, -1.3442e-01, -1.0597e+00, -5.6758e-01, -5.3127e-01,\n",
       "                      -9.8349e-01, -3.1408e-01, -7.8090e-01, -4.8889e-01,  9.2462e-01,\n",
       "                      -3.4522e-01, -3.9657e-01, -3.0505e-01,  1.6112e+00,  2.1258e+00,\n",
       "                       3.9128e-02, -8.6320e-01, -1.0973e+00, -2.6981e-01,  1.4686e+00,\n",
       "                      -1.4651e+00, -5.4465e-01,  1.5282e+00,  1.2464e+00,  1.9279e-01,\n",
       "                       4.0458e-01,  3.0796e-01, -8.9097e-01,  6.3258e-02,  8.0549e-01,\n",
       "                      -4.6129e-01, -6.4945e-01,  1.1298e+00, -9.0414e-01, -4.5251e-01,\n",
       "                      -2.1325e-01, -7.0149e-01, -6.5874e-01, -1.1518e+00, -1.1910e+00,\n",
       "                       6.4307e-01, -8.1313e-01,  2.6631e-03,  9.6918e-01, -3.9851e-01,\n",
       "                       9.8931e-01, -6.2109e-02, -7.8164e-01,  1.0631e-01,  4.9356e-01,\n",
       "                       2.8344e-01, -9.7565e-01, -4.1568e-03, -1.8253e+00,  3.3194e-01,\n",
       "                      -2.4947e+00, -1.1305e+00, -1.3351e+00, -4.6260e-01, -3.0033e-01,\n",
       "                      -3.5978e-01, -5.7411e-01,  8.2848e-01,  5.4139e-02,  2.8769e-01,\n",
       "                      -3.6178e-01, -2.8168e-01, -1.8051e+00, -1.1040e+00,  1.2012e-01,\n",
       "                       2.2230e+00, -5.0011e-01, -1.5385e+00,  5.6700e-01, -1.8290e+00,\n",
       "                       3.1052e-01, -1.8904e+00, -1.2605e-01,  1.3162e-01,  5.7755e-01,\n",
       "                      -3.0428e-01, -3.1018e-01,  4.1783e-01, -7.6296e-01, -4.7231e-01,\n",
       "                      -6.8103e-02,  1.5274e-01, -1.6153e+00,  6.3627e-01, -1.3199e-01,\n",
       "                      -1.4304e+00, -9.7683e-01,  2.6035e-01,  1.2584e+00,  4.1104e-01,\n",
       "                      -9.4646e-01,  4.9204e-01,  1.8775e+00, -1.1485e+00, -1.0581e+00,\n",
       "                      -2.2872e-01, -1.0322e-01, -5.4130e-01,  1.1354e-01,  2.9143e-01,\n",
       "                       1.5134e-01,  8.5876e-01,  1.1943e+00,  1.1627e+00,  1.7286e+00,\n",
       "                       4.5022e-01,  1.4690e+00,  2.4493e+00, -6.6128e-02,  2.0222e+00,\n",
       "                      -4.3650e-01,  1.3089e-01, -7.9821e-01,  1.2639e+00,  4.8627e-01,\n",
       "                      -4.8587e-01,  1.6724e+00, -3.5308e-01,  1.3873e+00, -4.4802e-01,\n",
       "                      -9.0845e-01,  6.3554e-01, -5.3676e-01,  5.8233e-01,  1.3942e+00,\n",
       "                       1.9765e+00,  4.3095e-01,  4.2367e-01, -6.3636e-02, -1.2617e+00,\n",
       "                      -3.0904e-01,  8.9475e-01,  4.7343e-01, -2.0006e-01, -1.5121e+00,\n",
       "                       1.5750e+00, -3.3136e-01,  1.3654e+00, -2.3413e+00, -1.7522e-01,\n",
       "                      -8.4448e-02,  5.7360e-01,  2.0341e-01, -1.1266e+00, -7.6609e-02,\n",
       "                      -6.1250e-01,  4.8552e-02,  1.7679e-01,  1.7698e+00, -5.1766e-01,\n",
       "                      -5.5754e-01,  2.6194e+00,  1.6418e+00, -2.4399e-01, -4.5452e-01,\n",
       "                       1.0241e+00, -1.2602e+00,  6.6334e-01,  4.2564e-01, -8.1422e-01,\n",
       "                      -2.6873e+00, -5.2530e-01, -8.4199e-01, -2.0999e-01,  1.2677e+00,\n",
       "                      -7.7537e-01,  7.0683e-01,  3.6910e-01, -1.1769e+00, -1.1032e+00,\n",
       "                       1.2252e+00,  6.9655e-01, -6.9549e-01, -1.0228e+00, -7.6534e-01,\n",
       "                      -2.3275e+00,  1.1367e+00, -1.0759e-01,  3.1531e-01,  2.1026e-01,\n",
       "                      -4.5944e-01, -1.1150e+00, -2.5314e-01, -1.3329e+00, -1.2388e-01,\n",
       "                       2.1475e-01, -2.2115e+00,  1.6839e+00, -4.8266e-01,  1.4260e+00,\n",
       "                      -1.5614e+00,  2.5002e-01, -3.7720e-01,  8.7607e-01,  2.4591e+00,\n",
       "                      -8.4623e-01,  1.5857e+00, -7.2823e-02, -7.6224e-01, -4.4718e-01,\n",
       "                       1.1322e+00, -5.3485e-01,  2.0402e+00, -2.0510e+00, -3.0682e-01,\n",
       "                      -1.3135e+00, -4.1375e-01,  9.0089e-01,  7.4734e-01,  1.0408e+00,\n",
       "                       6.8623e-01, -1.0678e+00, -3.0631e-01,  2.8903e-01,  1.0065e+00,\n",
       "                       1.3990e+00, -3.0028e-01, -4.4748e-01, -2.7924e+00,  2.4188e-01,\n",
       "                      -1.6639e+00,  1.3162e+00, -1.6140e+00, -1.1375e+00,  7.4788e-02,\n",
       "                       1.1246e+00,  1.0336e+00, -1.2429e-01, -1.9076e+00,  1.8155e-01,\n",
       "                       1.1307e-01, -2.1148e-01, -6.7909e-01,  1.1067e+00, -7.7051e-01,\n",
       "                      -1.2636e+00,  9.5325e-02, -2.2335e+00, -9.8958e-01, -1.3517e+00,\n",
       "                      -1.3092e+00, -2.6257e-01,  1.1159e+00,  7.8185e-01, -5.3012e-01])),\n",
       "             ('w2',\n",
       "              tensor([[-2.3325, -0.1072, -1.0074,  ..., -1.3378, -0.5155,  0.4705],\n",
       "                      [ 0.4139, -0.3501, -0.1933,  ..., -1.7931, -0.4819,  2.2257],\n",
       "                      [ 0.5778, -0.1227, -0.5234,  ...,  0.6608,  0.9044, -0.7223],\n",
       "                      ...,\n",
       "                      [ 0.1280,  0.6873,  0.8064,  ..., -0.9242, -0.4033, -0.4493],\n",
       "                      [ 1.1836, -1.5380,  0.5043,  ..., -1.4484,  1.5983,  1.9983],\n",
       "                      [-0.5458,  0.0528, -1.2086,  ...,  0.9683, -0.0334,  1.9465]])),\n",
       "             ('b2',\n",
       "              tensor([-0.7901, -0.6902,  0.8461, -0.8367,  2.2427,  1.8806, -1.3544, -1.3571,\n",
       "                      -2.3872, -0.5601, -0.5340, -0.4425, -0.0690, -0.9936,  1.5849,  1.1075,\n",
       "                      -0.2934, -0.4060,  0.7201,  0.1925,  1.3860,  1.5030,  1.0003,  0.0994,\n",
       "                       1.5238, -0.0921, -0.8507, -0.1241,  2.3084,  0.8754,  1.0706,  1.0198,\n",
       "                      -1.1649,  1.0584, -0.0780, -0.0213, -1.4360, -0.7617,  1.1928, -0.3577,\n",
       "                      -0.7038, -1.0224, -0.5905, -1.6146,  0.0248, -0.1729]))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.load(f='./trained_models/word2vec.ph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('pytorch': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69465f8012bc8209665d9cbe96a44652f48a74cf23ffa7f2a4d4373e52b4e5fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
